{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "09 GAN for fraud detection.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T8lgTOs-o0oW"
      },
      "source": [
        "# GAN for fraud detection\n",
        "In this notebook, we train a GAN network to generate more positive data points in order to inprove the accuracy of the fraud detection process."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WirOKAb4BXbL"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('seaborn')\n",
        "\n",
        "import xgboost as xgb\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn.metrics import recall_score, precision_score, roc_auc_score, accuracy_score, confusion_matrix\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M5juQ119_BAp"
      },
      "source": [
        "## Load data\n",
        "The datasets contains transactions made by credit cards in September 2013 by european cardholders.\n",
        "This dataset presents transactions that occurred in two days, where we have 492 (before duplicates are removed) frauds out of 284,807 (before duplicates are removed) transactions. The dataset is highly unbalanced, the positive class (frauds) account for 0.172% of all transactions.\n",
        "\n",
        "- It contains only numerical input variables which are the result of a PCA transformation. Features V1, V2, â€¦ V28 are the principal components obtained with PCA, the only features which have not been transformed with PCA are 'Time' and 'Amount'. \n",
        "\n",
        "- Feature 'Time' contains the seconds elapsed between each transaction and the first transaction in the dataset. \n",
        "- The feature 'Amount' is the transaction Amount, this feature can be used for example-dependant cost-senstive learning. \n",
        "- Feature 'Class' is the response variable and it takes value 1 in case of fraud and 0 otherwise."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_b-7RoujBnmg"
      },
      "source": [
        "df = pd.read_csv(\"/content/gdrive/My Drive/BT4012/Week 8/creditcard.csv\").drop_duplicates()\n",
        "print(df.shape)\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5Yez4vTA-Bb"
      },
      "source": [
        "df.Class.value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2_1kuL1ACK-6"
      },
      "source": [
        "This is a rather imbalanced dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ryvHC76ZA64N"
      },
      "source": [
        "# Exploratory Data Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yRec7qzIBtZI"
      },
      "source": [
        "# 'Time' is seconds from first transaction in set\n",
        "# 48 hours worth of data\n",
        "# Let's convert time to time of day, in hours\n",
        "\n",
        "df['Hour'] = (df['Time'].values // 3600 ) % 24\n",
        "\n",
        "print(f\"Last time value: {round(df['Time'].max() / 3600, 3)}\")\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.hist( [df.loc[df['Class']==0, 'Hour'], df.loc[df['Class']==1, 'Hour']],\n",
        "         density=True, label=['normal','fraud'], bins=np.linspace(0,24,25))\n",
        "plt.legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SmJmSsvXAsbU"
      },
      "source": [
        "Looks like normal transactions have a bias towards 8am to midnight and Fraud has spikes at 2-3am and noon."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tpvowkSxBCUE"
      },
      "source": [
        "# Log transform amount values to give more normal distribution\n",
        "\n",
        "plt.figure(figsize=(18,6))\n",
        "plt.subplot(1,2,1)\n",
        "plt.hist(df['Amount'], bins=40)\n",
        "plt.title('Original Amount Distribution')\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "d0 = np.log10(df['Amount'].values + 1 )\n",
        "plt.hist(d0, bins=40)\n",
        "plt.title('Log10(x+1) Transformed Amount Distribution')\n",
        "\n",
        "df['Amount'] = d0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SC2rU13qBwQz"
      },
      "source": [
        "# data columns will be all other columns except class\n",
        "data_cols = list(df.columns[df.columns != 'Class' ])\n",
        "\n",
        "print(data_cols)\n",
        "print('# of data columns: ',len(data_cols))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "thv_a2TEELLT"
      },
      "source": [
        "# Let's scale all numerical variables to standard normal variables\n",
        "\n",
        "df[data_cols] = StandardScaler().fit_transform(df[data_cols])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31EwbH33EvLJ"
      },
      "source": [
        "# Print the correlations between pair wise features\n",
        "plt.figure(figsize=(16, 13))\n",
        "corr0 = df.corr()\n",
        "sns.heatmap(corr0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQjjPYCxE2CI"
      },
      "source": [
        "Note no correlations among PCA transformed columns, as expected"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Lux_dD9Fmc-"
      },
      "source": [
        "# Plot the data distribution of each feature with respect to target variables\n",
        "\n",
        "axarr = [[]]*len(data_cols)\n",
        "columns = 4\n",
        "rows = int(np.ceil( len(data_cols) / columns))\n",
        "f, fig = plt.subplots(figsize=(columns*3.5, rows*2))\n",
        "\n",
        "f.suptitle('Data Distributions by Feature and Class', size=16)\n",
        "\n",
        "for i, col in enumerate(data_cols[:]):\n",
        "    axarr[i] = plt.subplot2grid((int(rows), int(columns)), (i//columns, i%columns))\n",
        "    axarr[i].hist([df.loc[df.Class == 0, col], df.loc[df.Class==1, col]], label=['normal', 'fraud'], \n",
        "                          bins=np.linspace(np.percentile(df[col], 0.1), np.percentile(df[col], 99.9), 30),\n",
        "                          density=True)\n",
        "    axarr[i].set_xlabel(col, size=12)\n",
        "    axarr[i].set_ylim([0,0.8])\n",
        "    axarr[i].tick_params(axis='both', labelsize=10)\n",
        "    if i == 0: \n",
        "        legend = axarr[i].legend()\n",
        "        legend.get_frame().set_facecolor('white')\n",
        "    if i%4 != 0: \n",
        "        axarr[i].tick_params(axis='y', left='off', labelleft='off')\n",
        "    else:\n",
        "        axarr[i].set_ylabel('Fraction',size=12)\n",
        "\n",
        "plt.tight_layout(rect=[0,0,1,0.95]) # xmin, ymin, xmax, ymax"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DGSMdwO0O9K8"
      },
      "source": [
        "We can observe that certain features (V14, V4, etc.) are more discrimitive than other features. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uL-DJF3oGIPK"
      },
      "source": [
        "# xgboost for fraud detection\n",
        "Let's build an xgboost classifier using these features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IqVkg7y6WFp5"
      },
      "source": [
        "# Set up the test and train sets\n",
        "# Use stratified train test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(df.drop('Class', axis=1), \n",
        "                                                    df['Class'], test_size=0.3, \n",
        "                                                    random_state=31, shuffle=True, \n",
        "                                                    stratify=df['Class'])\n",
        "\n",
        "dtrain, dtest = xgb.DMatrix(X_train, y_train, feature_names=data_cols), \\\n",
        "                xgb.DMatrix(X_test, y_test, feature_names=data_cols)\n",
        " \n",
        "\n",
        "# Run the xgboost algorithm, maximize recall on the test set\n",
        "results_dict = {}\n",
        "\n",
        "xgb_params = {\n",
        "    'objective': 'binary:logistic',\n",
        "    'random_state': 0,\n",
        "    'eval_metric': 'auc', \n",
        "}\n",
        "\n",
        "xgb_test = xgb.train(xgb_params, dtrain, num_boost_round=100, \n",
        "                     verbose_eval=False,\n",
        "                     early_stopping_rounds=20, \n",
        "                     evals=[(dtrain,'train'),(dtest,'test')],\n",
        "                     evals_result=results_dict            \n",
        "                    )\n",
        "\n",
        "y_pred = xgb_test.predict(dtest, ntree_limit=xgb_test.best_iteration+1)\n",
        "\n",
        "print(f'best iteration: {xgb_test.best_iteration}\\n')\n",
        "\n",
        "print(f'recall: {round(recall_score(y_test, np.round(y_pred)), 3)}')\n",
        "print(f'precision: {round(precision_score(y_test, np.round(y_pred)), 3)}')\n",
        "print(f'auc: {round(roc_auc_score(y_test, y_pred), 3)}\\n')\n",
        "\n",
        "print (confusion_matrix(y_test, np.round(y_pred)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TH5PYNgqK8_b"
      },
      "source": [
        "# Let's look at how the metrics changed on the train and test sets as more trees were added\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "for i in results_dict:\n",
        "    for err in results_dict[i]:\n",
        "        plt.plot(results_dict[i][err], label=i+' '+err)   \n",
        "\n",
        "plt.axvline(xgb_test.best_iteration, c='green', label='best iteration')\n",
        "plt.xlabel('iteration')\n",
        "plt.title('xgboost learning curves')\n",
        "plt.legend()\n",
        "plt.grid() ;"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I1WTKHkNNJrT"
      },
      "source": [
        "# Plot feature importances\n",
        "\n",
        "fig, ax = plt.subplots(1, 1, figsize=(8, 8))\n",
        "xgb.plot_importance(xgb_test, max_num_features=10, height=0.5, ax=ax);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r3YDXoLiWGi3"
      },
      "source": [
        "# Lets look at the effect of the ratio of normal:fraud data in the dataset on recall and roc_auc\n",
        "# We'll use cross validation to see if differences are significant\n",
        "\n",
        "n_test = np.sum(df.Class==1) # 473\n",
        "\n",
        "normal_samples = df[df.Class==0].sample(frac=1.0, random_state=11).reset_index(drop=True)\n",
        "fraud_samples = df[df.Class==1].sample(frac=1.0, random_state=11).reset_index(drop=True)\n",
        "\n",
        "test_data = []\n",
        "\n",
        "# 10%, 26%, 71%, ... 10000%\n",
        "\n",
        "for i in np.logspace(-1,2,8):\n",
        "    print(f'using {round(i*100, 3)}% normal data.' )\n",
        "    train_df = pd.concat([normal_samples[:int(n_test*i)], fraud_samples], ignore_index=True).reset_index(drop=True)\n",
        "    dtrain = xgb.DMatrix(train_df[data_cols], train_df['Class'], feature_names=data_cols)\n",
        "    results = xgb.cv(xgb_params, dtrain, nfold=5, num_boost_round=100, early_stopping_rounds=10, seed=0)\n",
        "    test_data.append(list([i]) + list(results.tail(1).index) + list(results.tail(1).values[0]))\n",
        "    \n",
        "test_data = pd.DataFrame(test_data, columns=list(['ratio','best']) + list(results.columns))\n",
        "test_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZ9dInqJXxOZ"
      },
      "source": [
        "metric = 'auc'\n",
        "xs = np.log10(test_data['ratio'].values)\n",
        "ys = test_data['test-'+metric+'-mean'].values\n",
        "stds = test_data['test-'+metric+'-std'].values\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.plot(xs,ys,c='C1')\n",
        "plt.plot(xs,ys+stds,linestyle=':',c='C2')\n",
        "plt.plot(xs,ys-stds,linestyle=':',c='C2')\n",
        "plt.xlabel('log10 ratio of normal:fraud data')\n",
        "plt.ylabel(metric)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IkC579lHCK_b"
      },
      "source": [
        "# Experiment with GAN model to generate additional data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KRaMVFeyB03T"
      },
      "source": [
        "from tensorflow.keras import applications\n",
        "from tensorflow.keras import backend\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import optimizers\n",
        "\n",
        "def generator_network(x, data_dim, base_n_count): \n",
        "    \"\"\"\n",
        "    Create a generator\n",
        "    x: input layer\n",
        "    data_dim: dimension of the data to be generated\n",
        "    base_n_count: base number of neurons of hidden layer\n",
        "    \"\"\"\n",
        "    x = layers.Dense(base_n_count, activation='relu')(x)\n",
        "    x = layers.Dense(base_n_count*2, activation='relu')(x)\n",
        "    x = layers.Dense(base_n_count*4, activation='relu')(x)\n",
        "    x = layers.Dense(data_dim)(x)    \n",
        "    return x\n",
        "\n",
        "def discriminator_network(x, base_n_count):\n",
        "    \"\"\"\n",
        "    Create a discriminator\n",
        "    x: input layer\n",
        "    base_n_count: base number of neurons of hidden layer\n",
        "    \"\"\"\n",
        "    x = layers.Dense(base_n_count*4, activation='relu')(x)\n",
        "    x = layers.Dense(base_n_count*2, activation='relu')(x)\n",
        "    x = layers.Dense(base_n_count, activation='relu')(x)\n",
        "    x = layers.Dense(1, activation='sigmoid')(x)\n",
        "    return x\n",
        "\n",
        "def define_models_GAN(rand_dim, data_dim, base_n_count):\n",
        "    \"\"\"\n",
        "    Create a GAN network and returns the generator part, the discriminator part and the whole network\n",
        "    rand_dim: random input dimension\n",
        "    data_dim: dimension of the data\n",
        "    base_n_count: base number of neurons of hidden layer\n",
        "    \"\"\"\n",
        "    \n",
        "    generator_input_tensor = layers.Input(shape=(rand_dim, ))\n",
        "    generated_data_tensor = generator_network(generator_input_tensor, data_dim, base_n_count)\n",
        "\n",
        "    generated_or_real_data_tensor = layers.Input(shape=(data_dim,))\n",
        "\n",
        "    discriminator_output = discriminator_network(generated_or_real_data_tensor, base_n_count)\n",
        "\n",
        "    generator_model = models.Model(inputs=[generator_input_tensor], \n",
        "                                   outputs=[generated_data_tensor], \n",
        "                                   name='generator')\n",
        "\n",
        "    discriminator_model = models.Model(inputs=[generated_or_real_data_tensor],\n",
        "                                      outputs=[discriminator_output],\n",
        "                                      name='discriminator')\n",
        "\n",
        "    combined_output = discriminator_model(generator_model(generator_input_tensor))\n",
        "    combined_model = models.Model(inputs=[generator_input_tensor], \n",
        "                                outputs=[combined_output], \n",
        "                                name='combined')\n",
        "\n",
        "    return generator_model, discriminator_model, combined_model   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nx1gG2uAH5AO"
      },
      "source": [
        "def PlotData(x, g_z, data_cols):\n",
        "    \"\"\"\n",
        "    Plot both the real data distribution and generated data distribution\n",
        "    x: real data\n",
        "    g_z: generated data\n",
        "    data_col: list of column names\n",
        "    \"\"\"\n",
        "    real_samples = pd.DataFrame(x, columns=data_cols)\n",
        "    gen_samples = pd.DataFrame(g_z, columns=data_cols)\n",
        "    \n",
        "    f, axarr = plt.subplots(1, 2, figsize=(6,2) )\n",
        "\n",
        "    axarr[0].scatter(real_samples[data_cols[0]], real_samples[data_cols[1]], cmap='plasma')\n",
        "    axarr[1].scatter(gen_samples[data_cols[0]], gen_samples[data_cols[1]], cmap='plasma')\n",
        "\n",
        "    axarr[0].set_title('real')\n",
        "    axarr[1].set_title('generated')   \n",
        "    \n",
        "    # Only add y label to left plot\n",
        "    axarr[0].set_ylabel(data_cols[1]) \n",
        "\n",
        "    for a in axarr: \n",
        "        a.set_xlabel(data_cols[0]) # Add x label to both plots\n",
        "\n",
        "    # Use axes ranges from real data for generated data\n",
        "    axarr[1].set_xlim(axarr[0].get_xlim()), axarr[1].set_ylim(axarr[0].get_ylim()) \n",
        "        \n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-76K0Nk0Hkk"
      },
      "source": [
        "def CheckAccuracy(x, g_z):    \n",
        "    \"\"\"\n",
        "    Compute the auc of the xgboost classifier that tries to seperate real from fake samples\n",
        "    Build a xgboost classifier to do discriminator's job \n",
        "    x: real data\n",
        "    g_z: generated data\n",
        "    \"\"\"\n",
        "    df_negative = pd.DataFrame(np.array(g_z))\n",
        "    df_negative.columns = x.columns\n",
        "    df_negative['label'] = 0\n",
        "    \n",
        "    x['label'] = 1\n",
        "\n",
        "    train_all = pd.concat([x, df_negative])\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(train_all.drop('label', axis=1), \n",
        "                                                        train_all['label'], \n",
        "                                                        test_size=0.3, \n",
        "                                                        random_state=31, \n",
        "                                                        shuffle=True)\n",
        "\n",
        "    dtrain = xgb.DMatrix(X_train, y_train, feature_names=train_all.columns[:-1])\n",
        "    dtest = xgb.DMatrix(X_test, feature_names=train_all.columns[:-1])\n",
        "    \n",
        "    xgb_params = {\n",
        "        'max_depth': 4, \n",
        "        'objective': 'binary:logistic',\n",
        "        'random_state': 0,\n",
        "        'eval_metric': 'auc',\n",
        "        }\n",
        "    \n",
        "    xgb_test = xgb.train(xgb_params, dtrain, num_boost_round=10) \n",
        "\n",
        "    y_pred = np.round(xgb_test.predict(dtest))\n",
        "\n",
        "    return roc_auc_score(y_test, y_pred) \n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKVDa8WrF4Dy"
      },
      "source": [
        "# Hyperparameters\n",
        "batch_size = 128\n",
        "rand_dim = 100\n",
        "learning_rate = 5e-4\n",
        "steps = 1000\n",
        "\n",
        "# Create the GAN network\n",
        "my_generator, my_discriminator, my_combined = define_models_GAN(rand_dim, len(data_cols), 128)\n",
        "adam = optimizers.Adam(lr=learning_rate, beta_1=0.5, beta_2=0.9)\n",
        "\n",
        "# compile models\n",
        "my_generator.compile(optimizer=adam, loss='binary_crossentropy')\n",
        "my_discriminator.compile(optimizer=adam, loss='binary_crossentropy')\n",
        "\n",
        "# Set the trainable attribute to False so that the discriminator part won't be updated for us to train the generator\n",
        "my_discriminator.trainable=False\n",
        "my_combined.compile(optimizer=adam, loss='binary_crossentropy')\n",
        "\n",
        "# We don't need the class information as GAN training is kind of self supervised\n",
        "train = df[df['Class']==1].copy().reset_index(drop=True).drop('Class', axis=1)\n",
        "\n",
        "# keep track of discriminator loss for positive samples and negative samples, generator loss and xgboost loss\n",
        "loss_d_p, loss_d_n, loss_g, xgb_losses = [], [], [], []\n",
        "\n",
        "for i in range(steps + 1):\n",
        "  # train the discriminator\n",
        "  for j in range(2):\n",
        "    z = np.random.normal(size=(batch_size, rand_dim))\n",
        "    x = train.sample(n=batch_size, random_state=i+j)\n",
        "    g_z = my_generator(z)\n",
        "    loss_d_p.append(my_discriminator.train_on_batch(x, np.random.uniform(low=0.999, high=1.0, size=batch_size))) # GANs need noise to prevent loss going to zero\n",
        "    loss_d_n.append(my_discriminator.train_on_batch(g_z, np.random.uniform(low=0.0, high=0.001, size=batch_size))) # GANs need noise to prevent loss going to zero\n",
        "\n",
        "  # train the generator\n",
        "  for j in range(2):\n",
        "    z = np.random.normal(size=(batch_size, rand_dim))\n",
        "    loss_g.append(my_combined.train_on_batch(z, np.random.uniform(low=0.999, high=1.0, size=batch_size))) # GANs need noise to prevent loss going to zero\n",
        "\n",
        "  # Determine xgb loss each step, after training generator and discriminator\n",
        "  if not i % 10: # 2x faster than testing each step...\n",
        "      x = train.sample(n=len(train), random_state=i)\n",
        "      z = np.random.normal(size=(len(train), rand_dim))\n",
        "      g_z = my_generator.predict(z)\n",
        "\n",
        "      # This xgboost classifier is doing the same job as the discriminator: differentiate real samples from the fake samples\n",
        "      xgb_losses.append(CheckAccuracy(x, g_z)) \n",
        "\n",
        "  # Saving weights and plotting images\n",
        "  if not i % 100:\n",
        "    print('Step: {} of {}.'.format(i, steps))         \n",
        "    my_generator.save_weights(f'generator_step_{i}.h5')\n",
        "    x = train.sample(n=len(train), random_state=0)\n",
        "    g_z = my_generator(np.random.normal(size=(len(train), rand_dim)))                   \n",
        "    PlotData(x, g_z, data_cols)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F7g5KOl919G5"
      },
      "source": [
        "# Plot the discriminator losses for positive and negative samples, generator loss and AUC of xgboost trying to seperate real from fake samples\n",
        "\n",
        "from scipy.signal import savgol_filter\n",
        "\n",
        "f, axarr = plt.subplots(2, 2, figsize=(10, 10))\n",
        "\n",
        "axarr[0][0].plot(savgol_filter(loss_d_p, 71, 3))\n",
        "axarr[0][1].plot(savgol_filter(loss_d_n, 71, 3))\n",
        "axarr[1][0].plot(savgol_filter(loss_g, 51, 3))\n",
        "axarr[1][1].plot(savgol_filter(xgb_losses, 11, 3))\n",
        "\n",
        "axarr[0][0].set_title('generator losses (positive)')\n",
        "axarr[0][1].set_title('generator losses (negative)')\n",
        "axarr[1][0].set_title('discriminator losses')  \n",
        "axarr[1][1].set_title('xgb AUC') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gulEmTegLglm"
      },
      "source": [
        "## We now use the generators trained before to see the effects of including these generated fraud data on a test dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TH5ZwXo03sIZ"
      },
      "source": [
        "def MakeCrossFolds(n_train_fraud, folds, g_z_df=[]):\n",
        "    \"\"\"\n",
        "    Generates list of train, test datasets with different \n",
        "    n_train_fraud: number of real fraud data to be used \n",
        "    folds: number of (train, test) pairs to generate\n",
        "    g_z_df: generated fraud dataframe\n",
        "    \"\"\"\n",
        "    train_fraction = 0.7\n",
        "    np.random.seed(0)\n",
        "\n",
        "    train_normal_set, test_normal_set = [], []\n",
        "    train_fraud_set, test_fraud_set = [], []\n",
        "\n",
        "    normal_samples = df[df.Class==0].copy()\n",
        "    fraud_samples = df[df.Class==1].copy()\n",
        "\n",
        "    # Generate folds sets of train/test splits\n",
        "    for seed in range(folds):\n",
        "        #########################################\n",
        "        # Prepare for fraud data                #\n",
        "        #########################################\n",
        "        # Shuffle the data\n",
        "        fraud_samples = fraud_samples.sample(frac=1.0, random_state=seed).reset_index(drop=True) \n",
        "\n",
        "        # Take the first n_train_fraud real fraud samples for training data\n",
        "        train_fraud_samples = fraud_samples[:n_train_fraud].reset_index(drop=True)\n",
        "\n",
        "        # Take the last n_test_fraud real fraud samples for testing data\n",
        "        # Note: there are 473 real fraud samples, int(473*0.3) = 141 < 373. So training and testing data have no overlaps.\n",
        "        n_test_fraud = int(len(fraud_samples) * (1-train_fraction)) \n",
        "        test_fraud_samples = fraud_samples[-n_test_fraud:].reset_index(drop=True)\n",
        "\n",
        "        # If there is no generated data provided, then we use the remaining real fraud data as training data. \n",
        "        if len(g_z_df)==0: \n",
        "            g_z_df = fraud_samples[n_train_fraud:-n_test_fraud] \n",
        "            \n",
        "        # append the generated fraud samples to the n_train_fraud real samples to form the fraud dataset for training\n",
        "        train_fraud_samples = train_fraud_samples.append(g_z_df).reset_index(drop=True)\n",
        "\n",
        "        #######################################\n",
        "        # Prepare for normal data             # \n",
        "        #######################################\n",
        "        # Shuffle the data\n",
        "        normal_samples = normal_samples.sample(frac=1.0, random_state=seed).reset_index(drop=True)\n",
        "\n",
        "        n_train_normal = int(len(normal_samples) * train_fraction)\n",
        "\n",
        "        # use the first n_train_normal normal data as training data and the remaining normal data as testing data\n",
        "        train_normal_samples = normal_samples[:n_train_normal].reset_index(drop=True)\n",
        "        test_normal_samples = normal_samples[n_train_normal:].reset_index(drop=True) \n",
        "        \n",
        "        train_normal_set.append(train_normal_samples)\n",
        "        test_normal_set.append(test_normal_samples)\n",
        "        train_fraud_set.append(train_fraud_samples)\n",
        "        test_fraud_set.append(test_fraud_samples)\n",
        "\n",
        "    print (f'Number of real fraud samples: {n_train_fraud}')\n",
        "    print (f'Number of generated fraud samples: {len(g_z_df)}')\n",
        "    print (f'Number of (real + generated) fraud samples in training data: {len(train_fraud_samples)}')\n",
        "    print (f'Number of real fraud samples in test data: {len(test_fraud_samples)}')\n",
        "    \n",
        "    return train_normal_set, test_normal_set, train_fraud_set, test_fraud_set\n",
        "\n",
        "\n",
        "\n",
        "def Run_CV_Xgb(limit, \n",
        "               folds, \n",
        "               n_train_fraud, \n",
        "               train_normal_set, \n",
        "               test_normal_set, \n",
        "               train_fraud_set, \n",
        "               test_fraud_set):\n",
        "    \"\"\"\n",
        "    Function to run an xgboost classifier on different cross-folds with different amounts of fake/real data added\n",
        "    limit: the maximum additional real/fake fraud data to be used\n",
        "    n_train_fraud: number of real fraud data to be used\n",
        "    train_real_set: dataframe of normal data for training\n",
        "    test_real_set: dataframe of normal data for testing\n",
        "    train_fraud_set: dataframe of fraud data for training\n",
        "    test_fraud_set: dataframe of fraud data for testing\n",
        "    \"\"\"\n",
        "    list_results = []\n",
        "    for i in np.logspace(0, np.log10(limit), num=5):\n",
        "        print(f'# additional generated data tested: {round((i-1)*100, 2)}%, which is {int((i-1)*n_train_fraud)} additional real/fake data')\n",
        "\n",
        "        for k in range(folds):\n",
        "            train_df = pd.concat(\n",
        "                [train_normal_set[k], train_fraud_set[k][:int(n_train_fraud*i)]], \n",
        "                ignore_index=True).reset_index(drop=True)\n",
        "            test_df = pd.concat( \n",
        "                [test_normal_set[k], test_fraud_set[k]],\n",
        "                ignore_index=True).reset_index(drop=True)\n",
        "\n",
        "            dtrain = xgb.DMatrix(train_df[data_cols], train_df['Class'], feature_names=data_cols)\n",
        "            dtest = xgb.DMatrix(test_df[data_cols], test_df['Class'], feature_names=data_cols)\n",
        "\n",
        "            results_dict = {}\n",
        "            xgb_test = xgb.train(xgb_params, dtrain, num_boost_round=100, \n",
        "                                 verbose_eval=False, early_stopping_rounds=10, \n",
        "                                 evals=[(dtrain,'train'), (dtest,'test')],\n",
        "                                 evals_result=results_dict \n",
        "                                 )\n",
        "\n",
        "            y_pred = xgb_test.predict(dtest, ntree_limit=xgb_test.best_iteration+1)\n",
        "            y_true = test_df['Class'].values     \n",
        "\n",
        "            results = [k, i, xgb_test.best_iteration, \n",
        "                       recall_score(y_true, np.round(y_pred)), \n",
        "                       precision_score(y_true, np.round(y_pred)), \n",
        "                       roc_auc_score(y_true, y_pred)]                            \n",
        "            list_results.append(results)\n",
        "\n",
        "    return pd.DataFrame(list_results, columns=['k', 'ratio','best','recall','precision','auc'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TA2qcCOZL-YY"
      },
      "source": [
        "np.random.seed(0)\n",
        "\n",
        "# n_train_fraud is the number of real fraud data used in the training data\n",
        "n_train_fraud = 100\n",
        "\n",
        "fold = 5\n",
        "\n",
        "# limit is the maximum multiple of training data used with respect to n_train_fraud\n",
        "# limit = (473 * 0.7) / 100 = 3.311\n",
        "limit = len(df[df.Class == 1]) * 0.7 / n_train_fraud\n",
        "\n",
        "#########################################################################\n",
        "# Use an early generator to generate additional data                    #\n",
        "#########################################################################\n",
        "# Generate len(train), which is 473 fake fraud data\n",
        "z = np.random.normal(size=(len(train), rand_dim))\n",
        "my_generator_early, _, _ = define_models_GAN(rand_dim, len(data_cols), 128)\n",
        "\n",
        "# Load a previously trained generator\n",
        "my_generator_early.load_weights('./generator_step_200.h5')\n",
        "\n",
        "# Generate fake fraud data using the generator\n",
        "g_z = my_generator_early.predict(z)\n",
        "\n",
        "# The labels for the generate data will all be 1, as they are supposed to be fraud data\n",
        "g_z_df = pd.DataFrame(g_z, columns=data_cols)\n",
        "g_z_df['Class'] = 1\n",
        "train_normal_set, test_normal_set, train_fraud_set, test_fraud_set = MakeCrossFolds(n_train_fraud, fold, g_z_df)\n",
        "t_early = Run_CV_Xgb(limit, fold, n_train_fraud, train_normal_set, test_normal_set, train_fraud_set, test_fraud_set)\n",
        "\n",
        "print ('\\n')\n",
        "#########################################################################\n",
        "# Use a late generator to generate additional data                      #\n",
        "#########################################################################\n",
        "\n",
        "# Generate len(train), which is 473 fake fraud data\n",
        "z = np.random.normal(size=(len(train), rand_dim))\n",
        "my_generator_late, _, _ = define_models_GAN(rand_dim, len(data_cols), 128)\n",
        "my_generator_late.load_weights('./generator_step_1000.h5')\n",
        "g_z = my_generator_late.predict(z)\n",
        "\n",
        "# The labels for the generate data will all be 1, as they are supposed to be fraud data\n",
        "g_z_df = pd.DataFrame(g_z, columns=data_cols )\n",
        "g_z_df['Class'] = 1\n",
        "train_normal_set, test_normal_set, train_fraud_set, test_fraud_set = MakeCrossFolds(n_train_fraud, fold, g_z_df)\n",
        "t_late = Run_CV_Xgb(limit, fold, n_train_fraud, train_normal_set, test_normal_set, train_fraud_set, test_fraud_set)\n",
        "\n",
        "print ('\\n')\n",
        "#########################################################################\n",
        "# Use all real fraud data to train the model                            #\n",
        "#########################################################################\n",
        "train_normal_set, test_normal_set, train_fraud_set, test_fraud_set = MakeCrossFolds(n_train_fraud, fold)\n",
        "t_real = Run_CV_Xgb(limit, fold, n_train_fraud, train_normal_set, test_normal_set, train_fraud_set, test_fraud_set)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "usisutUAfBrF"
      },
      "source": [
        "# Plot the results\n",
        "labels = ['trained 200 steps','trained 1000 steps','Actual Fraud Data']\n",
        "\n",
        "for metric in ['recall', 'auc', 'precision']:\n",
        "\n",
        "  plt.figure(figsize=(15,6))\n",
        "  for i, [label, test_data] in enumerate(zip(labels, [t_early, t_late, t_real])):\n",
        "\n",
        "      xs = [n_train_fraud * (ratio[0] - 1) for ratio in test_data.groupby('ratio')]\n",
        "      ys = test_data.groupby('ratio')[metric].mean().values\n",
        "      stds = test_data.groupby('ratio')[metric].std().values\n",
        "\n",
        "      plt.subplot(1,3,i+1)\n",
        "      plt.axhline(ys[0],linestyle='--',color='red')\n",
        "      plt.plot(xs,ys,c='C1',marker='o')\n",
        "      plt.plot(xs,ys+stds,linestyle=':',c='C2')\n",
        "      plt.plot(xs,ys-stds,linestyle=':',c='C2')\n",
        "      if i==0: \n",
        "          plt.ylabel(metric)\n",
        "      plt.xlabel('# additional data')\n",
        "      plt.title(label,size=12)\n",
        "      plt.ylim([0.6,1.0])\n",
        "\n",
        "  # plt.tight_layout(rect=[0,0,1,0.9])\n",
        "  plt.suptitle('Effects of additional data on fraud detection', size=16)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jw0GUEVHCK_y"
      },
      "source": [
        "## Impact of using additional generated fraud data on top of all real fraud data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQGCWZPlCK_y"
      },
      "source": [
        "# Set up the test and train sets\n",
        "# Use stratified train test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(df.drop('Class', axis=1), \n",
        "                                                    df['Class'], test_size=0.3, \n",
        "                                                    random_state=31, shuffle=True, \n",
        "                                                    stratify=df['Class'])\n",
        "\n",
        "dtrain, dtest = xgb.DMatrix(X_train, y_train, feature_names=data_cols), \\\n",
        "                xgb.DMatrix(X_test, y_test, feature_names=data_cols)\n",
        " \n",
        "\n",
        "# Run the xgboost algorithm, maximize recall on the test set\n",
        "results_dict = {}\n",
        "\n",
        "xgb_params = {\n",
        "    'objective': 'binary:logistic',\n",
        "    'random_state': 0,\n",
        "    'eval_metric': 'auc', \n",
        "}\n",
        "\n",
        "\n",
        "xgb_test = xgb.train(xgb_params, dtrain, num_boost_round=100, \n",
        "                     verbose_eval=False,\n",
        "                     early_stopping_rounds=20, \n",
        "                     evals=[(dtrain,'train')],\n",
        "                     evals_result=results_dict            \n",
        "                    )\n",
        "\n",
        "y_pred = xgb_test.predict(dtest, ntree_limit=xgb_test.best_iteration+1)\n",
        "\n",
        "print(f'best iteration: {xgb_test.best_iteration}\\n')\n",
        "\n",
        "print(f'recall: {round(recall_score(y_test, np.round(y_pred)), 3)}')\n",
        "print(f'precision: {round(precision_score(y_test, np.round(y_pred)), 3)}')\n",
        "print(f'auc: {round(roc_auc_score(y_test, y_pred), 3)}\\n')\n",
        "\n",
        "print (confusion_matrix(y_test, np.round(y_pred)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ctJCr0zYnn9I"
      },
      "source": [
        "def impact_with_more_training_data(X_train, \n",
        "                                   y_train, \n",
        "                                   X_test, \n",
        "                                   y_test, \n",
        "                                   multiplier, \n",
        "                                   rand_dim):\n",
        "    \"\"\"\n",
        "    X_train: features for training set\n",
        "    y_train: labels for training set\n",
        "    X_test: features for testing set\n",
        "    y_test: labels for testing set\n",
        "    multiple: additional training data used\n",
        "    \"\"\"\n",
        "    z = np.random.normal(size=(multiplier * len(df[df.Class==1]), rand_dim))\n",
        "    my_generator_late, _, _ = define_models_GAN(rand_dim, len(data_cols), 128)\n",
        "    my_generator_late.load_weights('./generator_step_800.h5')\n",
        "    g_z = my_generator_late.predict(z)\n",
        "    dtrain, dtest = xgb.DMatrix(np.vstack([X_train, g_z]), \n",
        "                                np.concatenate([y_train, np.ones(multiplier * len(df[df.Class==1]))]), \n",
        "                                feature_names=data_cols), \\\n",
        "                    xgb.DMatrix(X_test, y_test, feature_names=data_cols)\n",
        "\n",
        "    # Run the xgboost algorithm, maximize recall on the test set\n",
        "    results_dict = {}\n",
        "\n",
        "    xgb_params = {\n",
        "        'objective': 'binary:logistic',\n",
        "        'random_state': 0,\n",
        "        'eval_metric': 'auc', \n",
        "    }\n",
        "\n",
        "    xgb_test = xgb.train(xgb_params, dtrain, num_boost_round=100, \n",
        "                         verbose_eval=False,\n",
        "                         early_stopping_rounds=20, \n",
        "                         evals=[(dtrain,'train')],\n",
        "                         evals_result=results_dict            \n",
        "                        )\n",
        "\n",
        "    y_pred = xgb_test.predict(dtest, ntree_limit=xgb_test.best_iteration+1)\n",
        "\n",
        "    print(f'best iteration: {xgb_test.best_iteration}\\n')\n",
        "    print(f'recall: {round(recall_score(y_test, np.round(y_pred)), 3)}')\n",
        "    print(f'precision: {round(precision_score(y_test, np.round(y_pred)), 3)}')\n",
        "    print(f'auc: {round(roc_auc_score(y_test, y_pred), 3)}\\n')\n",
        "\n",
        "    return [recall_score(y_test, np.round(y_pred)), \n",
        "            precision_score(y_test, np.round(y_pred)), \n",
        "            roc_auc_score(y_test, y_pred)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r-nvhgd6CK_2"
      },
      "source": [
        "list_results = []\n",
        "\n",
        "for i in range(1, 101, 2):\n",
        "    print (f'Using {i}x of positive dataset')\n",
        "    list_results.append([i] + impact_with_more_training_data(X_train, y_train, X_test, y_test, i, rand_dim))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8GX1IAVCK_4"
      },
      "source": [
        "df_results = pd.DataFrame(list_results, columns=['multiplier', 'recall', 'precision', 'auc'])\n",
        "df_results.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oAjuT485CK_6"
      },
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(df_results['multiplier'], df_results['recall'], label='recall')\n",
        "plt.plot(df_results['multiplier'], df_results['precision'], label='precision')\n",
        "plt.plot(df_results['multiplier'], df_results['auc'], label='auc')\n",
        "plt.axhline(recall_score(y_test, np.round(y_pred)),linestyle='--',color='blue')\n",
        "plt.axhline(precision_score(y_test, np.round(y_pred)),linestyle='--',color='green')\n",
        "plt.axhline(roc_auc_score(y_test, y_pred),linestyle='--',color='red')\n",
        "plt.ylim([0.7,1.0])\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Effects of additional data')\n",
        "plt.xlabel('Multiplier')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}